services:
  rkllm-openai:
    # Use the image pulled from registry
    image: ghcr.io/huangyajie/rkllm-openai:latest
    container_name: rkllm-openai
    restart: unless-stopped
    
    # NPU Device Passthrough
    # CRITICAL: This allows the container to access the NPU hardware
    privileged: true
    devices:
      - /dev/dri:/dev/dri
    
    # Environment Variables
    # You can configure settings here or use a config file
    environment:
      - HOST=0.0.0.0
      - PORT=8080
      - CONFIG_FILE=/app/config/config.yaml
    
    # Volume Mounts
    volumes:
      # 1. Mount the RKLLM Runtime Library (REQUIRED)
      # Replace './lib/librkllmrt.so' with the actual path on your host
      - ./lib/librkllmrt.so:/app/lib/librkllmrt.so:ro
      
      # 2. Mount the Models Directory (REQUIRED)
      # Replace '../models' with your actual models directory
      - ./models:/app/models:ro

      # 3. Mount Configuration (Optional but recommended)
      - ./config.yaml:/app/config/config.yaml:ro
      
      # 4. Mount Logs (Optional)
      - ./logs:/app/logs
    
    ports:
      - "8080:8080"
    
    healthcheck:
      disable: true

